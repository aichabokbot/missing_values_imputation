{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data\n",
    "\n",
    "## Spark session creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob credentials at session creation\n",
    "\n",
    "It is possible to pass Azure SAS token directly when creating the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAS tokens\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import ContainerClient\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from blob_credentials import facts_sas_token, facts_container, workspace_sas_token, workspace_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname = \"Leo\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(f\"Test-{myname}\") \\\n",
    "    .config(\"spark.executor.instance\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\",\"512m\") \\\n",
    "    .config('spark.jars.packages',\"org.apache.hadoop:hadoop-azure:3.1.1\") \\\n",
    "    .config(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(\"fs.wasbs.impl\",\"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(f\"fs.azure.sas.{facts_container}.hecdf.blob.core.windows.net\", facts_sas_token) \\\n",
    "    .config(f\"fs.azure.sas.{workspace_container}.hecdf.blob.core.windows.net\", workspace_sas_token) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your blob services to access files on Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import ContainerClient\n",
    "\n",
    "account_url = \"https://hecdf.blob.core.windows.net\"\n",
    "\n",
    "facts_blob_service = ContainerClient(account_url=account_url,\n",
    "                                     container_name=facts_container,\n",
    "                                     credential=facts_sas_token)\n",
    "workspace_blob_service = ContainerClient(account_url=account_url,\n",
    "                                         container_name=workspace_container,\n",
    "                                         credential=workspace_sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List files from your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files in your workspace DO NOT FORGET your name prefix\n",
    "def list_my_files():\n",
    "    blobs = list(workspace_blob_service.list_blobs(myname))\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "\n",
    "# List the files in your whole group workspace\n",
    "def list_group_files():\n",
    "    blobs = list(workspace_blob_service.list_blobs())\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "\n",
    "# List the files in facts container\n",
    "def list_facts_files():\n",
    "    blobs = list(facts_blob_service.list_blobs())\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "list_facts_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy a file from/to your container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = list(facts_blob_service.list_blobs())\n",
    "\n",
    "for blob in blobs:\n",
    "    print(blob.name.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blobs = list(facts_blob_service.list_blobs())\n",
    "\n",
    "\n",
    "def get_name(file_path):\n",
    "    return file_path.name.split('/')[-1]\n",
    "\n",
    "\n",
    "def download_blob(blob_path, destination_dir):\n",
    "    \"\"\"\n",
    "    dowload file on azure\n",
    "    \"\"\"\n",
    "    blob_name = get_name(blob_path)\n",
    "    Path(f\"{destination_dir}/{blob_name}\").parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"{destination_dir}/{blob_name}\", \"wb\") as data:\n",
    "        download_stream = facts_blob_service.get_blob_client(blob_path).download_blob()\n",
    "        data.write(download_stream.readall())\n",
    "\n",
    "\n",
    "def download_blobs(facts_blob_service, destination_dir):\n",
    "    blobs = list(facts_blob_service.list_blobs())\n",
    "    for blob in blobs:\n",
    "        download_blob(blob, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_dir = \"../data\"\n",
    "download_blobs(facts_blob_service, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
